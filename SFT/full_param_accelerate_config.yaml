compute_environment: LOCAL_MACHINE
debug: false
deepspeed_config:
  train_batch_size: 1
  eval_batch_size: 1
  train_micro_batch_size_per_gpu: 1
  gradient_accumulation_steps: 1
  gradient_clipping: 1.0
  save_only_model: true
  save_strategy: epoch
  bf16:
    enabled: true
  zero_optimization:
    stage: 1
    offload_optimizer:
      device: cpu
      pin_memory: true
    allgather_partitions: true
    allgather_bucket_size: 5e8
    overlap_comm: true
    reduce_scatter: true
    reduce_bucket_size: 5e8
    contiguous_gradients: true
  optimizer:
    type: AdamW
    params:
      lr: 2.5e-5
      weight_decay: 0.1
      eps: 1e-8
      betas: [0.9, 0.999]
  steps_per_print: 10
  wall_clock_breakdown: false
distributed_type: DEEPSPEED
downcast_bf16: 'no'
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 8
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
